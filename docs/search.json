[
  {
    "objectID": "homework8.html",
    "href": "homework8.html",
    "title": "Homework 8",
    "section": "",
    "text": "This document demonstrates use of the principles and steps to make models in R:\n\nread data\ncheck the data\nsplit the data\nfit models\napply best model\n\n\n\n\n\nThis work relies heavily on tidymodels packages and related items, so we include this and the standard tidyverse code.\n\n\nWarning: package 'tidymodels' was built under R version 4.4.2\n\n\n── Attaching packages ────────────────────────────────────── tidymodels 1.2.0 ──\n\n\n✔ broom        1.0.6     ✔ recipes      1.1.0\n✔ dials        1.3.0     ✔ rsample      1.2.1\n✔ dplyr        1.1.4     ✔ tibble       3.2.1\n✔ ggplot2      3.5.1     ✔ tidyr        1.3.1\n✔ infer        1.0.7     ✔ tune         1.2.1\n✔ modeldata    1.4.0     ✔ workflows    1.1.4\n✔ parsnip      1.2.1     ✔ workflowsets 1.1.0\n✔ purrr        1.0.2     ✔ yardstick    1.3.1\n\n\nWarning: package 'dials' was built under R version 4.4.2\n\n\nWarning: package 'infer' was built under R version 4.4.2\n\n\nWarning: package 'modeldata' was built under R version 4.4.2\n\n\nWarning: package 'parsnip' was built under R version 4.4.2\n\n\nWarning: package 'recipes' was built under R version 4.4.2\n\n\nWarning: package 'rsample' was built under R version 4.4.2\n\n\nWarning: package 'tune' was built under R version 4.4.2\n\n\nWarning: package 'workflows' was built under R version 4.4.2\n\n\nWarning: package 'workflowsets' was built under R version 4.4.2\n\n\nWarning: package 'yardstick' was built under R version 4.4.2\n\n\n── Conflicts ───────────────────────────────────────── tidymodels_conflicts() ──\n✖ purrr::discard() masks scales::discard()\n✖ dplyr::filter()  masks stats::filter()\n✖ dplyr::lag()     masks stats::lag()\n✖ recipes::step()  masks stats::step()\n• Search for functions across packages at https://www.tidymodels.org/find/\n\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ forcats   1.0.0     ✔ readr     2.1.5\n✔ lubridate 1.9.3     ✔ stringr   1.5.1\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ readr::col_factor() masks scales::col_factor()\n✖ purrr::discard()    masks scales::discard()\n✖ dplyr::filter()     masks stats::filter()\n✖ stringr::fixed()    masks recipes::fixed()\n✖ dplyr::lag()        masks stats::lag()\n✖ readr::spec()       masks yardstick::spec()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n\nWarning: package 'corrr' was built under R version 4.4.2\n\n\n\n\n\nThe data comes from the UCI Machine Learning Repository. This set is about bike sharing rentals. More details available here. The data description describes the following variables:\n\n\n\n\n\n\n\nFIELD\nNOTES\n\n\n\n\nDate\nday/month/year\n\n\nRented Bike count\nCount of bikes rented at each hour\n\n\nHour\nHour of the day\n\n\nTemperature\nTemperature in Celsius\n\n\nHumidity\n%\n\n\nWindspeed\nm/s\n\n\nVisibility\n10m\n\n\nDew point temperature\nCelsius\n\n\nSolar radiation\nMJ/m2\n\n\nRainfall\nmm\n\n\nSnowfall\ncm\n\n\nSeasons\nWinter, Spring, Summer, Autumn\n\n\nHoliday\nHoliday/No holiday\n\n\nFunctional Day\nNoFunc(Non Functional Hours), Fun(Functional hours)\n\n\n\n\n\n\n\n\ndata_url &lt;- \"https://www4.stat.ncsu.edu/~online/datasets/SeoulBikeData.csv\"\ndata_raw &lt;- read_csv(\n  file = data_url, \n  locale = locale(encoding = \"latin1\")\n  )\n\nRows: 8760 Columns: 14\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (4): Date, Seasons, Holiday, Functioning Day\ndbl (10): Rented Bike Count, Hour, Temperature(°C), Humidity(%), Wind speed ...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\n\n\n\n\nNow, I need to review the data and clean it up, then summarize it.\n\n\n\ndata_raw |&gt; \n  map( ~sum(is.na(.)) )\n\n$Date\n[1] 0\n\n$`Rented Bike Count`\n[1] 0\n\n$Hour\n[1] 0\n\n$`Temperature(°C)`\n[1] 0\n\n$`Humidity(%)`\n[1] 0\n\n$`Wind speed (m/s)`\n[1] 0\n\n$`Visibility (10m)`\n[1] 0\n\n$`Dew point temperature(°C)`\n[1] 0\n\n$`Solar Radiation (MJ/m2)`\n[1] 0\n\n$`Rainfall(mm)`\n[1] 0\n\n$`Snowfall (cm)`\n[1] 0\n\n$Seasons\n[1] 0\n\n$Holiday\n[1] 0\n\n$`Functioning Day`\n[1] 0\n\n\nLooks ok, no missing values (NA).\n\n\n\nDo the column types look accurate?\n\nstr(data_raw)\n\nspc_tbl_ [8,760 × 14] (S3: spec_tbl_df/tbl_df/tbl/data.frame)\n $ Date                     : chr [1:8760] \"01/12/2017\" \"01/12/2017\" \"01/12/2017\" \"01/12/2017\" ...\n $ Rented Bike Count        : num [1:8760] 254 204 173 107 78 100 181 460 930 490 ...\n $ Hour                     : num [1:8760] 0 1 2 3 4 5 6 7 8 9 ...\n $ Temperature(°C)          : num [1:8760] -5.2 -5.5 -6 -6.2 -6 -6.4 -6.6 -7.4 -7.6 -6.5 ...\n $ Humidity(%)              : num [1:8760] 37 38 39 40 36 37 35 38 37 27 ...\n $ Wind speed (m/s)         : num [1:8760] 2.2 0.8 1 0.9 2.3 1.5 1.3 0.9 1.1 0.5 ...\n $ Visibility (10m)         : num [1:8760] 2000 2000 2000 2000 2000 ...\n $ Dew point temperature(°C): num [1:8760] -17.6 -17.6 -17.7 -17.6 -18.6 -18.7 -19.5 -19.3 -19.8 -22.4 ...\n $ Solar Radiation (MJ/m2)  : num [1:8760] 0 0 0 0 0 0 0 0 0.01 0.23 ...\n $ Rainfall(mm)             : num [1:8760] 0 0 0 0 0 0 0 0 0 0 ...\n $ Snowfall (cm)            : num [1:8760] 0 0 0 0 0 0 0 0 0 0 ...\n $ Seasons                  : chr [1:8760] \"Winter\" \"Winter\" \"Winter\" \"Winter\" ...\n $ Holiday                  : chr [1:8760] \"No Holiday\" \"No Holiday\" \"No Holiday\" \"No Holiday\" ...\n $ Functioning Day          : chr [1:8760] \"Yes\" \"Yes\" \"Yes\" \"Yes\" ...\n - attr(*, \"spec\")=\n  .. cols(\n  ..   Date = col_character(),\n  ..   `Rented Bike Count` = col_double(),\n  ..   Hour = col_double(),\n  ..   `Temperature(°C)` = col_double(),\n  ..   `Humidity(%)` = col_double(),\n  ..   `Wind speed (m/s)` = col_double(),\n  ..   `Visibility (10m)` = col_double(),\n  ..   `Dew point temperature(°C)` = col_double(),\n  ..   `Solar Radiation (MJ/m2)` = col_double(),\n  ..   `Rainfall(mm)` = col_double(),\n  ..   `Snowfall (cm)` = col_double(),\n  ..   Seasons = col_character(),\n  ..   Holiday = col_character(),\n  ..   `Functioning Day` = col_character()\n  .. )\n - attr(*, \"problems\")=&lt;externalptr&gt; \n\n\nObservations and updates required:\n\nSwitch type to Date:\n\nDate\n\nSwitch type to Integer:\n\nRented Bike Count\nHour\n\nSwitch character lists to Factor:\n\nSeasons\nHoliday\nFunctioning Day\n\nRename to remove spaces across most fields\n\nDo the numerical summaries look reasonable?\n\ndata_raw |&gt;\n  select(where(is.numeric)) |&gt;\n  psych::describe() |&gt;\n  select(\n    min,\n    max,\n    range,\n    median,\n    sd\n    )\n\n                            min     max   range  median     sd\nRented Bike Count           0.0 3556.00 3556.00  504.50 645.00\nHour                        0.0   23.00   23.00   11.50   6.92\nTemperature(°C)           -17.8   39.40   57.20   13.70  11.94\nHumidity(%)                 0.0   98.00   98.00   57.00  20.36\nWind speed (m/s)            0.0    7.40    7.40    1.50   1.04\nVisibility (10m)           27.0 2000.00 1973.00 1698.00 608.30\nDew point temperature(°C) -30.6   27.20   57.80    5.10  13.06\nSolar Radiation (MJ/m2)     0.0    3.52    3.52    0.01   0.87\nRainfall(mm)                0.0   35.00   35.00    0.00   1.13\nSnowfall (cm)               0.0    8.80    8.80    0.00   0.44\n\n\nNothing looks unreasonable in the numeric variable spread.\nDo the categorical variable values look reasonable?\n\ndata_raw |&gt;\n  select(where(is_character),-Date) |&gt;\n  map(unique)\n\n$Seasons\n[1] \"Winter\" \"Spring\" \"Summer\" \"Autumn\"\n\n$Holiday\n[1] \"No Holiday\" \"Holiday\"   \n\n$`Functioning Day`\n[1] \"Yes\" \"No\" \n\n\nUnique categorical values look fine as well.\n\n\n\nNow, let’s fix the Date field format.\n\ndata_raw &lt;- data_raw |&gt;\n  mutate(Date = as_date(Date,format=\"%d/%m/%Y\"))\nstr(data_raw$Date)\n\n Date[1:8760], format: \"2017-12-01\" \"2017-12-01\" \"2017-12-01\" \"2017-12-01\" \"2017-12-01\" ...\n\n\n\n\n\nNext, turn character fields into factors.\n\ndata_raw &lt;- data_raw |&gt;\n  mutate(\n    Seasons = as_factor(Seasons),\n    Holiday = as_factor(Holiday),\n    `Functioning Day` = as_factor(`Functioning Day`)\n    )\nstr(select(data_raw,where(is.factor)))\n\ntibble [8,760 × 3] (S3: tbl_df/tbl/data.frame)\n $ Seasons        : Factor w/ 4 levels \"Winter\",\"Spring\",..: 1 1 1 1 1 1 1 1 1 1 ...\n $ Holiday        : Factor w/ 2 levels \"No Holiday\",\"Holiday\": 1 1 1 1 1 1 1 1 1 1 ...\n $ Functioning Day: Factor w/ 2 levels \"Yes\",\"No\": 1 1 1 1 1 1 1 1 1 1 ...\n\n\nAlso, here, I will change the previously-noted fields into integers.\n\ndata_raw &lt;- data_raw |&gt;\n  mutate(\n    `Rented Bike Count` = as.integer(`Rented Bike Count`),\n    Hour = as.integer(Hour)\n    )\nstr(select(data_raw,where(is_integer)))\n\ntibble [8,760 × 5] (S3: tbl_df/tbl/data.frame)\n $ Rented Bike Count: int [1:8760] 254 204 173 107 78 100 181 460 930 490 ...\n $ Hour             : int [1:8760] 0 1 2 3 4 5 6 7 8 9 ...\n $ Seasons          : Factor w/ 4 levels \"Winter\",\"Spring\",..: 1 1 1 1 1 1 1 1 1 1 ...\n $ Holiday          : Factor w/ 2 levels \"No Holiday\",\"Holiday\": 1 1 1 1 1 1 1 1 1 1 ...\n $ Functioning Day  : Factor w/ 2 levels \"Yes\",\"No\": 1 1 1 1 1 1 1 1 1 1 ...\n\n\n\n\n\nAnd lastly, cleaning up the names for easier work without encoding.\n\ndata_raw &lt;- data_raw |&gt;\n  mutate(\n    BikeCount = `Rented Bike Count`,\n    Temperature = `Temperature(°C)`,\n    Humidity = `Humidity(%)`,\n    WindSpeed = `Wind speed (m/s)`,\n    Visibility = `Visibility (10m)`,\n    DewPoint = `Dew point temperature(°C)`,\n    SolarRadiation = `Solar Radiation (MJ/m2)`,\n    Rainfall = `Rainfall(mm)`,\n    Snowfall = `Snowfall (cm)`,\n    FunctioningDay = `Functioning Day`,         \n    .keep='unused'\n    )\nstr(data_raw)\n\ntibble [8,760 × 14] (S3: tbl_df/tbl/data.frame)\n $ Date          : Date[1:8760], format: \"2017-12-01\" \"2017-12-01\" ...\n $ Hour          : int [1:8760] 0 1 2 3 4 5 6 7 8 9 ...\n $ Seasons       : Factor w/ 4 levels \"Winter\",\"Spring\",..: 1 1 1 1 1 1 1 1 1 1 ...\n $ Holiday       : Factor w/ 2 levels \"No Holiday\",\"Holiday\": 1 1 1 1 1 1 1 1 1 1 ...\n $ BikeCount     : int [1:8760] 254 204 173 107 78 100 181 460 930 490 ...\n $ Temperature   : num [1:8760] -5.2 -5.5 -6 -6.2 -6 -6.4 -6.6 -7.4 -7.6 -6.5 ...\n $ Humidity      : num [1:8760] 37 38 39 40 36 37 35 38 37 27 ...\n $ WindSpeed     : num [1:8760] 2.2 0.8 1 0.9 2.3 1.5 1.3 0.9 1.1 0.5 ...\n $ Visibility    : num [1:8760] 2000 2000 2000 2000 2000 ...\n $ DewPoint      : num [1:8760] -17.6 -17.6 -17.7 -17.6 -18.6 -18.7 -19.5 -19.3 -19.8 -22.4 ...\n $ SolarRadiation: num [1:8760] 0 0 0 0 0 0 0 0 0.01 0.23 ...\n $ Rainfall      : num [1:8760] 0 0 0 0 0 0 0 0 0 0 ...\n $ Snowfall      : num [1:8760] 0 0 0 0 0 0 0 0 0 0 ...\n $ FunctioningDay: Factor w/ 2 levels \"Yes\",\"No\": 1 1 1 1 1 1 1 1 1 1 ...\n\n\n\n\n\nNow, to display some summaries of the tidied data. Numeric summaries and then categorical contingency tables.\n\ndata_raw |&gt;\n  select(where(is.numeric)) |&gt;\n  psych::describe() |&gt;\n  select(\n    min,\n    max,\n    range,\n    median,\n    sd\n    )\n\n                 min     max   range  median     sd\nHour             0.0   23.00   23.00   11.50   6.92\nBikeCount        0.0 3556.00 3556.00  504.50 645.00\nTemperature    -17.8   39.40   57.20   13.70  11.94\nHumidity         0.0   98.00   98.00   57.00  20.36\nWindSpeed        0.0    7.40    7.40    1.50   1.04\nVisibility      27.0 2000.00 1973.00 1698.00 608.30\nDewPoint       -30.6   27.20   57.80    5.10  13.06\nSolarRadiation   0.0    3.52    3.52    0.01   0.87\nRainfall         0.0   35.00   35.00    0.00   1.13\nSnowfall         0.0    8.80    8.80    0.00   0.44\n\n\nNothing stands out here, as noted earlier. Now, to contingency tables for categorical variables.\n\ndata_raw |&gt;\n  group_by(Seasons) |&gt;\n  summarize(n())\n\n# A tibble: 4 × 2\n  Seasons `n()`\n  &lt;fct&gt;   &lt;int&gt;\n1 Winter   2160\n2 Spring   2208\n3 Summer   2208\n4 Autumn   2184\n\n\n\ndata_raw |&gt;\n  group_by(Holiday) |&gt;\n  summarize(n())\n\n# A tibble: 2 × 2\n  Holiday    `n()`\n  &lt;fct&gt;      &lt;int&gt;\n1 No Holiday  8328\n2 Holiday      432\n\n\n\ndata_raw |&gt;\n  group_by(FunctioningDay) |&gt;\n  summarize(n())\n\n# A tibble: 2 × 2\n  FunctioningDay `n()`\n  &lt;fct&gt;          &lt;int&gt;\n1 Yes             8465\n2 No               295\n\n\n\ndata_raw |&gt;\n  group_by(FunctioningDay,Seasons) |&gt;\n  summarize(n())\n\n`summarise()` has grouped output by 'FunctioningDay'. You can override using\nthe `.groups` argument.\n\n\n# A tibble: 6 × 3\n# Groups:   FunctioningDay [2]\n  FunctioningDay Seasons `n()`\n  &lt;fct&gt;          &lt;fct&gt;   &lt;int&gt;\n1 Yes            Winter   2160\n2 Yes            Spring   2160\n3 Yes            Summer   2208\n4 Yes            Autumn   1937\n5 No             Spring     48\n6 No             Autumn    247\n\n\nI don’t understand truly what the FunctioningDay field means. The notes say it is a target / response variable, but exactly how to interpret that is unclear to me. I’ll check grouping by this field.\n\ndata_raw |&gt;\n  group_by(FunctioningDay) |&gt;\n  summarize(\n    Min=min(BikeCount),\n    Max=max(BikeCount),\n    Avg=mean(BikeCount)\n    )\n\n# A tibble: 2 × 4\n  FunctioningDay   Min   Max   Avg\n  &lt;fct&gt;          &lt;int&gt; &lt;int&gt; &lt;dbl&gt;\n1 Yes                2  3556  729.\n2 No                 0     0    0 \n\n\nOh, it is simply an indicator of when bikes were available. I presume we do not want to study the days when bikes did not allow usage, so now we will subset to remove those days (FunctioningDay = No).\n\ndata_raw &lt;- data_raw |&gt;\n  filter(FunctioningDay == 'Yes')\n\n\n\n\nNow for simplicity, we adjust our data to summarize across hours so that each day has only one observation associated with it.\n\ndata &lt;- data_raw |&gt;\n  group_by(Date,\n           Seasons,\n           Holiday\n           ) |&gt;\n  summarize(\n    BikeCountSum = sum(BikeCount),\n    RainfallSum = sum(Rainfall),\n    SnowfallSum = sum(Snowfall),\n    TemperatureAvg = mean(Temperature),\n    HumidityAvg = mean(Humidity),\n    WindSpeedAvg = mean(WindSpeed),\n    VisibilityAvg = mean(Visibility),\n    DewPointAvg = mean(DewPoint),\n    SolarRadiationAvg = mean(SolarRadiation)\n    ) |&gt;\n  select(\n    Date,\n    Seasons,\n    Holiday,\n    ends_with(\"Sum\"),\n    ends_with(\"Avg\")\n  )\n\n`summarise()` has grouped output by 'Date', 'Seasons'. You can override using\nthe `.groups` argument.\n\nhead(data)\n\n# A tibble: 6 × 12\n# Groups:   Date, Seasons [6]\n  Date       Seasons Holiday BikeCountSum RainfallSum SnowfallSum TemperatureAvg\n  &lt;date&gt;     &lt;fct&gt;   &lt;fct&gt;          &lt;int&gt;       &lt;dbl&gt;       &lt;dbl&gt;          &lt;dbl&gt;\n1 2017-12-01 Winter  No Hol…         9539         0           0          -2.45  \n2 2017-12-02 Winter  No Hol…         8523         0           0           1.32  \n3 2017-12-03 Winter  No Hol…         7222         4           0           4.88  \n4 2017-12-04 Winter  No Hol…         8729         0.1         0          -0.304 \n5 2017-12-05 Winter  No Hol…         8307         0           0          -4.46  \n6 2017-12-06 Winter  No Hol…         6669         1.3         8.6         0.0458\n# ℹ 5 more variables: HumidityAvg &lt;dbl&gt;, WindSpeedAvg &lt;dbl&gt;,\n#   VisibilityAvg &lt;dbl&gt;, DewPointAvg &lt;dbl&gt;, SolarRadiationAvg &lt;dbl&gt;\n\n\n\n\n\nNow, to restate summaries of the updated dataset.\n\ndata |&gt;\n  select(where(is.numeric)) |&gt;\n  psych::describe() |&gt;\n  select(\n    min,\n    max,\n    range,\n    median,\n    sd\n    )\n\nAdding missing grouping variables: `Date`, `Seasons`\n\n\nWarning in FUN(newX[, i], ...): no non-missing arguments to min; returning Inf\n\n\nWarning in FUN(newX[, i], ...): no non-missing arguments to max; returning -Inf\n\n\n                     min      max    range   median      sd\nDate                 Inf     -Inf     -Inf       NA      NA\nSeasons*            1.00     4.00     3.00     2.00    1.11\nBikeCountSum      977.00 36149.00 35172.00 18563.00 9937.16\nRainfallSum         0.00    95.50    95.50     0.00   11.79\nSnowfallSum         0.00    78.70    78.70     0.00    8.80\nTemperatureAvg    -14.74    33.74    48.48    13.74   11.72\nHumidityAvg        22.25    95.88    73.62    57.17   14.87\nWindSpeedAvg        0.66     4.00     3.34     1.66    0.60\nVisibilityAvg     214.29  2000.00  1785.71  1557.75  491.16\nDewPointAvg       -27.75    25.04    52.79     4.61   12.99\nSolarRadiationAvg   0.03     1.22     1.19     0.56    0.32\n\n\nLet’s visualize this information a few ways - with box and whiskers as well as scatterplots.\n\ng &lt;- data |&gt;\n  ggplot()\ng + \n  geom_boxplot(\n    aes(\n      x=Seasons,\n      y=BikeCountSum,\n      color=Holiday\n    )\n  ) + \n  labs(\n    title=\"Bike Counts per Season by Holiday\"\n    )\n\n\n\n\n\n\n\n\nOn holidays, across all seasons, fewer bikes are used. However, the variation in range of max and min bikes used is much smaller on holidays. So, as a light interpretation notwithstanding the much smaller sample size of Holiday data, we might assess that holidays do garner a tight range of activity, consistently.\n\ng + \n  geom_point(\n    aes(\n      x=TemperatureAvg,\n      y=BikeCountSum\n    )\n  ) + \n  labs(\n    title=\"Bike Counts vs Temperature\"\n    ) +\n  facet_grid(~Seasons)\n\n\n\n\n\n\n\n\nThe shapes here are interesting. In Winter, no matter the temperature, few bikes are used. In the spring, where it can be a bit cool to a bit warm, the number of bikes used quickly grows. In the summer, in high temperatures consistently, if temperature raises slightly, bike rentals decrease rapidly. Autumn is comparable to Spring in shape and range.\nLastly, we display correlations for all numeric variables.\n\ndata |&gt;\n  select(where(is.numeric)) |&gt;\n  correlate() |&gt;\n  shave() |&gt;\n  rplot()\n\nAdding missing grouping variables: `Date`, `Seasons`\nNon-numeric variables removed from input: `Date`, and `Seasons`\nCorrelation computed with • Method: 'pearson' • Missing treated using:\n'pairwise.complete.obs'\n\n\n\n\n\n\n\n\n\nThis package corrr has cool features, including this color-coded display of all correlations between numeric variables. Immediately, we can see the strongest relationships with Bike Counts are the Temperature, Dew Point, and Solar Radiation. It’s likely those are interrelated and tell the same story (evidenced by the strong correlation between Temperature and Dew Point shown in the chart, elsewhere). The strongest negative correlation between non-result variables is that of Humidity and Visibility. I don’t normally think of humidity impacting visibility, so that’s interesting; is it because of pollution or am I simply unaware that wet air does impede visibility, perhaps at longer distances?\n\n\n\n\nTo analyze this data, which is small, we will split into training and test and then use 10-fold CV. In the split, we will use the strata argument to ensure a fair sample across the seasons variable.\n\ndata_split &lt;- initial_split(data, prop = 0.75, strata = Seasons)\ndata_train &lt;- training(data_split)\ndata_test &lt;- testing(data_split)\ndata_train_10Fold &lt;- vfold_cv(data_train, 10)\n\n\n\n\n\n\nFirst recipe, ignore Date and instead work with weekday/weekend factor. Then standardize numeric variables to make comparable scales. Create dummy variables for seasons, holiday, and the day type.\n\nrecipe1 &lt;- recipe(BikeCountSum ~ ., data = data_train) |&gt;\n  \n  #Date into weekend/weekday\n  step_date(Date) |&gt;\n  step_mutate(\n    Weekday_Weekend = factor(if_else(\n      (Date_dow == \"Sat\") | (Date_dow == \"Sun\"),\n      \"Weekend\",\n      \"Weekday\")\n      )\n    ) |&gt;\n  \n  #remove excess original Date fields\n  step_rm(c(Date,\n            Date_dow,\n            Date_month,\n            Date_year)\n          ) |&gt;\n  \n  #normalize numerics\n  step_normalize(\n    all_numeric(),\n    -all_outcomes()\n    ) |&gt;\n  \n  #dummy vars for categorical items\n  step_dummy(c(Seasons,\n               Holiday,\n               Weekday_Weekend)\n             ) |&gt;\n  \n  #clean up names\n  step_rename(\n    isHoliday = Holiday_Holiday,\n    isWeekend = Weekday_Weekend_Weekend,\n    isSummerSeason = Seasons_Summer,\n    isSpringSeason = Seasons_Spring,\n    isAutumnSeason = Seasons_Autumn\n  )\n    \n    \n   # ) |&gt;  prep(training=data_train) |&gt;\n #bake(data_train)\n#testing |&gt; summary()\n\n\n\n\nFor this recipe, we start with Recipe 1 and add interaction terms between:\n\nseasons and holiday\nseasons and temp\ntemp and rainfall\n\n\nrecipe2 &lt;- recipe1 |&gt;\n  step_interact(terms = ~\n                  ends_with(\"Season\") *\n                  ends_with(\"Holiday\") \n                ) |&gt;\n  step_interact(terms = ~\n                  ends_with(\"Season\") *\n                  TemperatureAvg\n                ) |&gt;\n  step_interact(terms = ~\n                  TemperatureAvg *\n                  RainfallSum\n                ) \n\n\n\n\nFor the third recipe, start from Recipe 2 and add quadratic terms for each numeric predictor. Since our dummy variables are technically numeric now, I’m excluding them by avoiding all those beginning with is (like isSpring, etc.).\n\nrecipe3 &lt;- recipe2 |&gt;\n  step_poly(\n    all_numeric_predictors(),\n    -starts_with(\"is\"),\n    degree=2\n    )\n\n\n\n\nWe will fit the models using linear lm engine and use 10-fold CV to calculate error.\nFirst, define the model engine.\n\ndata_model &lt;- linear_reg() |&gt;\n  set_engine(\"lm\")\n\nNext, define workflows for each recipe.\n\ndata_workflow1 &lt;- workflow() |&gt;\n  add_recipe(recipe1) |&gt;\n  add_model(data_model)\n\ndata_workflow2 &lt;- workflow() |&gt;\n  add_recipe(recipe2) |&gt;\n  add_model(data_model)\n\ndata_workflow3 &lt;- workflow() |&gt;\n  add_recipe(recipe3) |&gt;\n  add_model(data_model)\n\nNow, define and run the 10-fold CV for each. Out of curiosity, I am going to compare to a non-CV run as well.\n\n#non-CV for simple recipe 1\ndata_fit_nonCV &lt;- data_workflow1 |&gt;\n  fit(data_train)\n\n#data_fit_nonCV |&gt;\n# tidy()\n\n#10fold CV for each recipe\nrecipe1_10Fold_metrics &lt;- data_workflow1 |&gt;\n  fit_resamples(data_train_10Fold) |&gt;\n  collect_metrics()\n\nrecipe2_10Fold_metrics &lt;- data_workflow2 |&gt;\n  fit_resamples(data_train_10Fold) |&gt;\n  collect_metrics()\n\n→ A | warning: prediction from rank-deficient fit; consider predict(., rankdeficient=\"NA\")\n\n\nThere were issues with some computations   A: x1\nThere were issues with some computations   A: x1\n\n\n\n\nrecipe3_10Fold_metrics &lt;- data_workflow3 |&gt;\n  fit_resamples(data_train_10Fold) |&gt;\n  collect_metrics()\n\n→ A | warning: prediction from rank-deficient fit; consider predict(., rankdeficient=\"NA\")\n\n\nThere were issues with some computations   A: x1\nThere were issues with some computations   A: x1\n\n\n\n\nrbind(\n  recipe1_10Fold_metrics,\n  recipe2_10Fold_metrics,\n  recipe3_10Fold_metrics\n)\n\n# A tibble: 6 × 6\n  .metric .estimator     mean     n  std_err .config             \n  &lt;chr&gt;   &lt;chr&gt;         &lt;dbl&gt; &lt;int&gt;    &lt;dbl&gt; &lt;chr&gt;               \n1 rmse    standard   4070.       10 165.     Preprocessor1_Model1\n2 rsq     standard      0.840    10   0.0106 Preprocessor1_Model1\n3 rmse    standard   3074.       10 252.     Preprocessor1_Model1\n4 rsq     standard      0.900    10   0.0184 Preprocessor1_Model1\n5 rmse    standard   2984.       10 196.     Preprocessor1_Model1\n6 rsq     standard      0.907    10   0.0152 Preprocessor1_Model1\n\n\nThe best model of the three looks like the third recipe, with interaction terms and quadratic terms.\n\n\n\n\nNow, let’s fit it to the entire training dataset and compute RMSE.\n\nbest_fit &lt;- data_workflow3 |&gt;\n  last_fit(data_split)\nbest_fit |&gt; collect_metrics()\n\n# A tibble: 2 × 4\n  .metric .estimator .estimate .config             \n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt; &lt;chr&gt;               \n1 rmse    standard    2964.    Preprocessor1_Model1\n2 rsq     standard       0.910 Preprocessor1_Model1\n\n\nHere is the coefficient table for our model, arranged by p-values to highlight the most predictive parameters.\n\nextract_fit_parsnip(best_fit) |&gt; tidy() |&gt; arrange(p.value)\n\n# A tibble: 30 × 5\n   term                            estimate std.error statistic  p.value\n   &lt;chr&gt;                              &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n 1 isSummerSeason                    24955.     2078.     12.0  3.53e-26\n 2 SolarRadiationAvg_poly_1          54739.     5764.      9.50 2.74e-18\n 3 isWeekend                         -2458.      411.     -5.98 8.21e- 9\n 4 isAutumnSeason                    11823.     2268.      5.21 4.09e- 7\n 5 isSpringSeason_x_TemperatureAvg   10048.     2464.      4.08 6.23e- 5\n 6 RainfallSum_poly_1               -34844.     8953.     -3.89 1.30e- 4\n 7 (Intercept)                        9828.     2675.      3.67 2.97e- 4\n 8 isSpringSeason                     6669.     2170.      3.07 2.36e- 3\n 9 HumidityAvg_poly_1               -56014.    24608.     -2.28 2.37e- 2\n10 DewPointAvg_poly_1               173117.    82435.      2.10 3.68e- 2\n# ℹ 20 more rows\n\n\nSo, recalling what we are doing here - predicting bike rental volume - it is interesting to note the predictors most likely to relate to bike rental volumes. I think that’s what the lowest p-values represent here, the likelihood that this was a random relationship (slope of zero) with the outcome.\n\nif we are in summer, we are likely to see more rentals\nsolar radiation increases with rentals, too (related to summer)\non the weekend, we are less likely to see rentals? That surprises me, so I checked my setup to be sure.\nif raining, less bikes; this makes sense."
  },
  {
    "objectID": "homework8.html#context",
    "href": "homework8.html#context",
    "title": "Homework 8",
    "section": "",
    "text": "This work relies heavily on tidymodels packages and related items, so we include this and the standard tidyverse code.\n\n\nWarning: package 'tidymodels' was built under R version 4.4.2\n\n\n── Attaching packages ────────────────────────────────────── tidymodels 1.2.0 ──\n\n\n✔ broom        1.0.6     ✔ recipes      1.1.0\n✔ dials        1.3.0     ✔ rsample      1.2.1\n✔ dplyr        1.1.4     ✔ tibble       3.2.1\n✔ ggplot2      3.5.1     ✔ tidyr        1.3.1\n✔ infer        1.0.7     ✔ tune         1.2.1\n✔ modeldata    1.4.0     ✔ workflows    1.1.4\n✔ parsnip      1.2.1     ✔ workflowsets 1.1.0\n✔ purrr        1.0.2     ✔ yardstick    1.3.1\n\n\nWarning: package 'dials' was built under R version 4.4.2\n\n\nWarning: package 'infer' was built under R version 4.4.2\n\n\nWarning: package 'modeldata' was built under R version 4.4.2\n\n\nWarning: package 'parsnip' was built under R version 4.4.2\n\n\nWarning: package 'recipes' was built under R version 4.4.2\n\n\nWarning: package 'rsample' was built under R version 4.4.2\n\n\nWarning: package 'tune' was built under R version 4.4.2\n\n\nWarning: package 'workflows' was built under R version 4.4.2\n\n\nWarning: package 'workflowsets' was built under R version 4.4.2\n\n\nWarning: package 'yardstick' was built under R version 4.4.2\n\n\n── Conflicts ───────────────────────────────────────── tidymodels_conflicts() ──\n✖ purrr::discard() masks scales::discard()\n✖ dplyr::filter()  masks stats::filter()\n✖ dplyr::lag()     masks stats::lag()\n✖ recipes::step()  masks stats::step()\n• Search for functions across packages at https://www.tidymodels.org/find/\n\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ forcats   1.0.0     ✔ readr     2.1.5\n✔ lubridate 1.9.3     ✔ stringr   1.5.1\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ readr::col_factor() masks scales::col_factor()\n✖ purrr::discard()    masks scales::discard()\n✖ dplyr::filter()     masks stats::filter()\n✖ stringr::fixed()    masks recipes::fixed()\n✖ dplyr::lag()        masks stats::lag()\n✖ readr::spec()       masks yardstick::spec()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n\nWarning: package 'corrr' was built under R version 4.4.2\n\n\n\n\n\nThe data comes from the UCI Machine Learning Repository. This set is about bike sharing rentals. More details available here. The data description describes the following variables:\n\n\n\n\n\n\n\nFIELD\nNOTES\n\n\n\n\nDate\nday/month/year\n\n\nRented Bike count\nCount of bikes rented at each hour\n\n\nHour\nHour of the day\n\n\nTemperature\nTemperature in Celsius\n\n\nHumidity\n%\n\n\nWindspeed\nm/s\n\n\nVisibility\n10m\n\n\nDew point temperature\nCelsius\n\n\nSolar radiation\nMJ/m2\n\n\nRainfall\nmm\n\n\nSnowfall\ncm\n\n\nSeasons\nWinter, Spring, Summer, Autumn\n\n\nHoliday\nHoliday/No holiday\n\n\nFunctional Day\nNoFunc(Non Functional Hours), Fun(Functional hours)"
  },
  {
    "objectID": "homework8.html#read-data",
    "href": "homework8.html#read-data",
    "title": "Homework 8",
    "section": "",
    "text": "data_url &lt;- \"https://www4.stat.ncsu.edu/~online/datasets/SeoulBikeData.csv\"\ndata_raw &lt;- read_csv(\n  file = data_url, \n  locale = locale(encoding = \"latin1\")\n  )\n\nRows: 8760 Columns: 14\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (4): Date, Seasons, Holiday, Functioning Day\ndbl (10): Rented Bike Count, Hour, Temperature(°C), Humidity(%), Wind speed ...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message."
  },
  {
    "objectID": "homework8.html#eda",
    "href": "homework8.html#eda",
    "title": "Homework 8",
    "section": "",
    "text": "Now, I need to review the data and clean it up, then summarize it.\n\n\n\ndata_raw |&gt; \n  map( ~sum(is.na(.)) )\n\n$Date\n[1] 0\n\n$`Rented Bike Count`\n[1] 0\n\n$Hour\n[1] 0\n\n$`Temperature(°C)`\n[1] 0\n\n$`Humidity(%)`\n[1] 0\n\n$`Wind speed (m/s)`\n[1] 0\n\n$`Visibility (10m)`\n[1] 0\n\n$`Dew point temperature(°C)`\n[1] 0\n\n$`Solar Radiation (MJ/m2)`\n[1] 0\n\n$`Rainfall(mm)`\n[1] 0\n\n$`Snowfall (cm)`\n[1] 0\n\n$Seasons\n[1] 0\n\n$Holiday\n[1] 0\n\n$`Functioning Day`\n[1] 0\n\n\nLooks ok, no missing values (NA).\n\n\n\nDo the column types look accurate?\n\nstr(data_raw)\n\nspc_tbl_ [8,760 × 14] (S3: spec_tbl_df/tbl_df/tbl/data.frame)\n $ Date                     : chr [1:8760] \"01/12/2017\" \"01/12/2017\" \"01/12/2017\" \"01/12/2017\" ...\n $ Rented Bike Count        : num [1:8760] 254 204 173 107 78 100 181 460 930 490 ...\n $ Hour                     : num [1:8760] 0 1 2 3 4 5 6 7 8 9 ...\n $ Temperature(°C)          : num [1:8760] -5.2 -5.5 -6 -6.2 -6 -6.4 -6.6 -7.4 -7.6 -6.5 ...\n $ Humidity(%)              : num [1:8760] 37 38 39 40 36 37 35 38 37 27 ...\n $ Wind speed (m/s)         : num [1:8760] 2.2 0.8 1 0.9 2.3 1.5 1.3 0.9 1.1 0.5 ...\n $ Visibility (10m)         : num [1:8760] 2000 2000 2000 2000 2000 ...\n $ Dew point temperature(°C): num [1:8760] -17.6 -17.6 -17.7 -17.6 -18.6 -18.7 -19.5 -19.3 -19.8 -22.4 ...\n $ Solar Radiation (MJ/m2)  : num [1:8760] 0 0 0 0 0 0 0 0 0.01 0.23 ...\n $ Rainfall(mm)             : num [1:8760] 0 0 0 0 0 0 0 0 0 0 ...\n $ Snowfall (cm)            : num [1:8760] 0 0 0 0 0 0 0 0 0 0 ...\n $ Seasons                  : chr [1:8760] \"Winter\" \"Winter\" \"Winter\" \"Winter\" ...\n $ Holiday                  : chr [1:8760] \"No Holiday\" \"No Holiday\" \"No Holiday\" \"No Holiday\" ...\n $ Functioning Day          : chr [1:8760] \"Yes\" \"Yes\" \"Yes\" \"Yes\" ...\n - attr(*, \"spec\")=\n  .. cols(\n  ..   Date = col_character(),\n  ..   `Rented Bike Count` = col_double(),\n  ..   Hour = col_double(),\n  ..   `Temperature(°C)` = col_double(),\n  ..   `Humidity(%)` = col_double(),\n  ..   `Wind speed (m/s)` = col_double(),\n  ..   `Visibility (10m)` = col_double(),\n  ..   `Dew point temperature(°C)` = col_double(),\n  ..   `Solar Radiation (MJ/m2)` = col_double(),\n  ..   `Rainfall(mm)` = col_double(),\n  ..   `Snowfall (cm)` = col_double(),\n  ..   Seasons = col_character(),\n  ..   Holiday = col_character(),\n  ..   `Functioning Day` = col_character()\n  .. )\n - attr(*, \"problems\")=&lt;externalptr&gt; \n\n\nObservations and updates required:\n\nSwitch type to Date:\n\nDate\n\nSwitch type to Integer:\n\nRented Bike Count\nHour\n\nSwitch character lists to Factor:\n\nSeasons\nHoliday\nFunctioning Day\n\nRename to remove spaces across most fields\n\nDo the numerical summaries look reasonable?\n\ndata_raw |&gt;\n  select(where(is.numeric)) |&gt;\n  psych::describe() |&gt;\n  select(\n    min,\n    max,\n    range,\n    median,\n    sd\n    )\n\n                            min     max   range  median     sd\nRented Bike Count           0.0 3556.00 3556.00  504.50 645.00\nHour                        0.0   23.00   23.00   11.50   6.92\nTemperature(°C)           -17.8   39.40   57.20   13.70  11.94\nHumidity(%)                 0.0   98.00   98.00   57.00  20.36\nWind speed (m/s)            0.0    7.40    7.40    1.50   1.04\nVisibility (10m)           27.0 2000.00 1973.00 1698.00 608.30\nDew point temperature(°C) -30.6   27.20   57.80    5.10  13.06\nSolar Radiation (MJ/m2)     0.0    3.52    3.52    0.01   0.87\nRainfall(mm)                0.0   35.00   35.00    0.00   1.13\nSnowfall (cm)               0.0    8.80    8.80    0.00   0.44\n\n\nNothing looks unreasonable in the numeric variable spread.\nDo the categorical variable values look reasonable?\n\ndata_raw |&gt;\n  select(where(is_character),-Date) |&gt;\n  map(unique)\n\n$Seasons\n[1] \"Winter\" \"Spring\" \"Summer\" \"Autumn\"\n\n$Holiday\n[1] \"No Holiday\" \"Holiday\"   \n\n$`Functioning Day`\n[1] \"Yes\" \"No\" \n\n\nUnique categorical values look fine as well.\n\n\n\nNow, let’s fix the Date field format.\n\ndata_raw &lt;- data_raw |&gt;\n  mutate(Date = as_date(Date,format=\"%d/%m/%Y\"))\nstr(data_raw$Date)\n\n Date[1:8760], format: \"2017-12-01\" \"2017-12-01\" \"2017-12-01\" \"2017-12-01\" \"2017-12-01\" ...\n\n\n\n\n\nNext, turn character fields into factors.\n\ndata_raw &lt;- data_raw |&gt;\n  mutate(\n    Seasons = as_factor(Seasons),\n    Holiday = as_factor(Holiday),\n    `Functioning Day` = as_factor(`Functioning Day`)\n    )\nstr(select(data_raw,where(is.factor)))\n\ntibble [8,760 × 3] (S3: tbl_df/tbl/data.frame)\n $ Seasons        : Factor w/ 4 levels \"Winter\",\"Spring\",..: 1 1 1 1 1 1 1 1 1 1 ...\n $ Holiday        : Factor w/ 2 levels \"No Holiday\",\"Holiday\": 1 1 1 1 1 1 1 1 1 1 ...\n $ Functioning Day: Factor w/ 2 levels \"Yes\",\"No\": 1 1 1 1 1 1 1 1 1 1 ...\n\n\nAlso, here, I will change the previously-noted fields into integers.\n\ndata_raw &lt;- data_raw |&gt;\n  mutate(\n    `Rented Bike Count` = as.integer(`Rented Bike Count`),\n    Hour = as.integer(Hour)\n    )\nstr(select(data_raw,where(is_integer)))\n\ntibble [8,760 × 5] (S3: tbl_df/tbl/data.frame)\n $ Rented Bike Count: int [1:8760] 254 204 173 107 78 100 181 460 930 490 ...\n $ Hour             : int [1:8760] 0 1 2 3 4 5 6 7 8 9 ...\n $ Seasons          : Factor w/ 4 levels \"Winter\",\"Spring\",..: 1 1 1 1 1 1 1 1 1 1 ...\n $ Holiday          : Factor w/ 2 levels \"No Holiday\",\"Holiday\": 1 1 1 1 1 1 1 1 1 1 ...\n $ Functioning Day  : Factor w/ 2 levels \"Yes\",\"No\": 1 1 1 1 1 1 1 1 1 1 ...\n\n\n\n\n\nAnd lastly, cleaning up the names for easier work without encoding.\n\ndata_raw &lt;- data_raw |&gt;\n  mutate(\n    BikeCount = `Rented Bike Count`,\n    Temperature = `Temperature(°C)`,\n    Humidity = `Humidity(%)`,\n    WindSpeed = `Wind speed (m/s)`,\n    Visibility = `Visibility (10m)`,\n    DewPoint = `Dew point temperature(°C)`,\n    SolarRadiation = `Solar Radiation (MJ/m2)`,\n    Rainfall = `Rainfall(mm)`,\n    Snowfall = `Snowfall (cm)`,\n    FunctioningDay = `Functioning Day`,         \n    .keep='unused'\n    )\nstr(data_raw)\n\ntibble [8,760 × 14] (S3: tbl_df/tbl/data.frame)\n $ Date          : Date[1:8760], format: \"2017-12-01\" \"2017-12-01\" ...\n $ Hour          : int [1:8760] 0 1 2 3 4 5 6 7 8 9 ...\n $ Seasons       : Factor w/ 4 levels \"Winter\",\"Spring\",..: 1 1 1 1 1 1 1 1 1 1 ...\n $ Holiday       : Factor w/ 2 levels \"No Holiday\",\"Holiday\": 1 1 1 1 1 1 1 1 1 1 ...\n $ BikeCount     : int [1:8760] 254 204 173 107 78 100 181 460 930 490 ...\n $ Temperature   : num [1:8760] -5.2 -5.5 -6 -6.2 -6 -6.4 -6.6 -7.4 -7.6 -6.5 ...\n $ Humidity      : num [1:8760] 37 38 39 40 36 37 35 38 37 27 ...\n $ WindSpeed     : num [1:8760] 2.2 0.8 1 0.9 2.3 1.5 1.3 0.9 1.1 0.5 ...\n $ Visibility    : num [1:8760] 2000 2000 2000 2000 2000 ...\n $ DewPoint      : num [1:8760] -17.6 -17.6 -17.7 -17.6 -18.6 -18.7 -19.5 -19.3 -19.8 -22.4 ...\n $ SolarRadiation: num [1:8760] 0 0 0 0 0 0 0 0 0.01 0.23 ...\n $ Rainfall      : num [1:8760] 0 0 0 0 0 0 0 0 0 0 ...\n $ Snowfall      : num [1:8760] 0 0 0 0 0 0 0 0 0 0 ...\n $ FunctioningDay: Factor w/ 2 levels \"Yes\",\"No\": 1 1 1 1 1 1 1 1 1 1 ...\n\n\n\n\n\nNow, to display some summaries of the tidied data. Numeric summaries and then categorical contingency tables.\n\ndata_raw |&gt;\n  select(where(is.numeric)) |&gt;\n  psych::describe() |&gt;\n  select(\n    min,\n    max,\n    range,\n    median,\n    sd\n    )\n\n                 min     max   range  median     sd\nHour             0.0   23.00   23.00   11.50   6.92\nBikeCount        0.0 3556.00 3556.00  504.50 645.00\nTemperature    -17.8   39.40   57.20   13.70  11.94\nHumidity         0.0   98.00   98.00   57.00  20.36\nWindSpeed        0.0    7.40    7.40    1.50   1.04\nVisibility      27.0 2000.00 1973.00 1698.00 608.30\nDewPoint       -30.6   27.20   57.80    5.10  13.06\nSolarRadiation   0.0    3.52    3.52    0.01   0.87\nRainfall         0.0   35.00   35.00    0.00   1.13\nSnowfall         0.0    8.80    8.80    0.00   0.44\n\n\nNothing stands out here, as noted earlier. Now, to contingency tables for categorical variables.\n\ndata_raw |&gt;\n  group_by(Seasons) |&gt;\n  summarize(n())\n\n# A tibble: 4 × 2\n  Seasons `n()`\n  &lt;fct&gt;   &lt;int&gt;\n1 Winter   2160\n2 Spring   2208\n3 Summer   2208\n4 Autumn   2184\n\n\n\ndata_raw |&gt;\n  group_by(Holiday) |&gt;\n  summarize(n())\n\n# A tibble: 2 × 2\n  Holiday    `n()`\n  &lt;fct&gt;      &lt;int&gt;\n1 No Holiday  8328\n2 Holiday      432\n\n\n\ndata_raw |&gt;\n  group_by(FunctioningDay) |&gt;\n  summarize(n())\n\n# A tibble: 2 × 2\n  FunctioningDay `n()`\n  &lt;fct&gt;          &lt;int&gt;\n1 Yes             8465\n2 No               295\n\n\n\ndata_raw |&gt;\n  group_by(FunctioningDay,Seasons) |&gt;\n  summarize(n())\n\n`summarise()` has grouped output by 'FunctioningDay'. You can override using\nthe `.groups` argument.\n\n\n# A tibble: 6 × 3\n# Groups:   FunctioningDay [2]\n  FunctioningDay Seasons `n()`\n  &lt;fct&gt;          &lt;fct&gt;   &lt;int&gt;\n1 Yes            Winter   2160\n2 Yes            Spring   2160\n3 Yes            Summer   2208\n4 Yes            Autumn   1937\n5 No             Spring     48\n6 No             Autumn    247\n\n\nI don’t understand truly what the FunctioningDay field means. The notes say it is a target / response variable, but exactly how to interpret that is unclear to me. I’ll check grouping by this field.\n\ndata_raw |&gt;\n  group_by(FunctioningDay) |&gt;\n  summarize(\n    Min=min(BikeCount),\n    Max=max(BikeCount),\n    Avg=mean(BikeCount)\n    )\n\n# A tibble: 2 × 4\n  FunctioningDay   Min   Max   Avg\n  &lt;fct&gt;          &lt;int&gt; &lt;int&gt; &lt;dbl&gt;\n1 Yes                2  3556  729.\n2 No                 0     0    0 \n\n\nOh, it is simply an indicator of when bikes were available. I presume we do not want to study the days when bikes did not allow usage, so now we will subset to remove those days (FunctioningDay = No).\n\ndata_raw &lt;- data_raw |&gt;\n  filter(FunctioningDay == 'Yes')\n\n\n\n\nNow for simplicity, we adjust our data to summarize across hours so that each day has only one observation associated with it.\n\ndata &lt;- data_raw |&gt;\n  group_by(Date,\n           Seasons,\n           Holiday\n           ) |&gt;\n  summarize(\n    BikeCountSum = sum(BikeCount),\n    RainfallSum = sum(Rainfall),\n    SnowfallSum = sum(Snowfall),\n    TemperatureAvg = mean(Temperature),\n    HumidityAvg = mean(Humidity),\n    WindSpeedAvg = mean(WindSpeed),\n    VisibilityAvg = mean(Visibility),\n    DewPointAvg = mean(DewPoint),\n    SolarRadiationAvg = mean(SolarRadiation)\n    ) |&gt;\n  select(\n    Date,\n    Seasons,\n    Holiday,\n    ends_with(\"Sum\"),\n    ends_with(\"Avg\")\n  )\n\n`summarise()` has grouped output by 'Date', 'Seasons'. You can override using\nthe `.groups` argument.\n\nhead(data)\n\n# A tibble: 6 × 12\n# Groups:   Date, Seasons [6]\n  Date       Seasons Holiday BikeCountSum RainfallSum SnowfallSum TemperatureAvg\n  &lt;date&gt;     &lt;fct&gt;   &lt;fct&gt;          &lt;int&gt;       &lt;dbl&gt;       &lt;dbl&gt;          &lt;dbl&gt;\n1 2017-12-01 Winter  No Hol…         9539         0           0          -2.45  \n2 2017-12-02 Winter  No Hol…         8523         0           0           1.32  \n3 2017-12-03 Winter  No Hol…         7222         4           0           4.88  \n4 2017-12-04 Winter  No Hol…         8729         0.1         0          -0.304 \n5 2017-12-05 Winter  No Hol…         8307         0           0          -4.46  \n6 2017-12-06 Winter  No Hol…         6669         1.3         8.6         0.0458\n# ℹ 5 more variables: HumidityAvg &lt;dbl&gt;, WindSpeedAvg &lt;dbl&gt;,\n#   VisibilityAvg &lt;dbl&gt;, DewPointAvg &lt;dbl&gt;, SolarRadiationAvg &lt;dbl&gt;\n\n\n\n\n\nNow, to restate summaries of the updated dataset.\n\ndata |&gt;\n  select(where(is.numeric)) |&gt;\n  psych::describe() |&gt;\n  select(\n    min,\n    max,\n    range,\n    median,\n    sd\n    )\n\nAdding missing grouping variables: `Date`, `Seasons`\n\n\nWarning in FUN(newX[, i], ...): no non-missing arguments to min; returning Inf\n\n\nWarning in FUN(newX[, i], ...): no non-missing arguments to max; returning -Inf\n\n\n                     min      max    range   median      sd\nDate                 Inf     -Inf     -Inf       NA      NA\nSeasons*            1.00     4.00     3.00     2.00    1.11\nBikeCountSum      977.00 36149.00 35172.00 18563.00 9937.16\nRainfallSum         0.00    95.50    95.50     0.00   11.79\nSnowfallSum         0.00    78.70    78.70     0.00    8.80\nTemperatureAvg    -14.74    33.74    48.48    13.74   11.72\nHumidityAvg        22.25    95.88    73.62    57.17   14.87\nWindSpeedAvg        0.66     4.00     3.34     1.66    0.60\nVisibilityAvg     214.29  2000.00  1785.71  1557.75  491.16\nDewPointAvg       -27.75    25.04    52.79     4.61   12.99\nSolarRadiationAvg   0.03     1.22     1.19     0.56    0.32\n\n\nLet’s visualize this information a few ways - with box and whiskers as well as scatterplots.\n\ng &lt;- data |&gt;\n  ggplot()\ng + \n  geom_boxplot(\n    aes(\n      x=Seasons,\n      y=BikeCountSum,\n      color=Holiday\n    )\n  ) + \n  labs(\n    title=\"Bike Counts per Season by Holiday\"\n    )\n\n\n\n\n\n\n\n\nOn holidays, across all seasons, fewer bikes are used. However, the variation in range of max and min bikes used is much smaller on holidays. So, as a light interpretation notwithstanding the much smaller sample size of Holiday data, we might assess that holidays do garner a tight range of activity, consistently.\n\ng + \n  geom_point(\n    aes(\n      x=TemperatureAvg,\n      y=BikeCountSum\n    )\n  ) + \n  labs(\n    title=\"Bike Counts vs Temperature\"\n    ) +\n  facet_grid(~Seasons)\n\n\n\n\n\n\n\n\nThe shapes here are interesting. In Winter, no matter the temperature, few bikes are used. In the spring, where it can be a bit cool to a bit warm, the number of bikes used quickly grows. In the summer, in high temperatures consistently, if temperature raises slightly, bike rentals decrease rapidly. Autumn is comparable to Spring in shape and range.\nLastly, we display correlations for all numeric variables.\n\ndata |&gt;\n  select(where(is.numeric)) |&gt;\n  correlate() |&gt;\n  shave() |&gt;\n  rplot()\n\nAdding missing grouping variables: `Date`, `Seasons`\nNon-numeric variables removed from input: `Date`, and `Seasons`\nCorrelation computed with • Method: 'pearson' • Missing treated using:\n'pairwise.complete.obs'\n\n\n\n\n\n\n\n\n\nThis package corrr has cool features, including this color-coded display of all correlations between numeric variables. Immediately, we can see the strongest relationships with Bike Counts are the Temperature, Dew Point, and Solar Radiation. It’s likely those are interrelated and tell the same story (evidenced by the strong correlation between Temperature and Dew Point shown in the chart, elsewhere). The strongest negative correlation between non-result variables is that of Humidity and Visibility. I don’t normally think of humidity impacting visibility, so that’s interesting; is it because of pollution or am I simply unaware that wet air does impede visibility, perhaps at longer distances?\n\n\n\n\nTo analyze this data, which is small, we will split into training and test and then use 10-fold CV. In the split, we will use the strata argument to ensure a fair sample across the seasons variable.\n\ndata_split &lt;- initial_split(data, prop = 0.75, strata = Seasons)\ndata_train &lt;- training(data_split)\ndata_test &lt;- testing(data_split)\ndata_train_10Fold &lt;- vfold_cv(data_train, 10)\n\n\n\n\n\n\nFirst recipe, ignore Date and instead work with weekday/weekend factor. Then standardize numeric variables to make comparable scales. Create dummy variables for seasons, holiday, and the day type.\n\nrecipe1 &lt;- recipe(BikeCountSum ~ ., data = data_train) |&gt;\n  \n  #Date into weekend/weekday\n  step_date(Date) |&gt;\n  step_mutate(\n    Weekday_Weekend = factor(if_else(\n      (Date_dow == \"Sat\") | (Date_dow == \"Sun\"),\n      \"Weekend\",\n      \"Weekday\")\n      )\n    ) |&gt;\n  \n  #remove excess original Date fields\n  step_rm(c(Date,\n            Date_dow,\n            Date_month,\n            Date_year)\n          ) |&gt;\n  \n  #normalize numerics\n  step_normalize(\n    all_numeric(),\n    -all_outcomes()\n    ) |&gt;\n  \n  #dummy vars for categorical items\n  step_dummy(c(Seasons,\n               Holiday,\n               Weekday_Weekend)\n             ) |&gt;\n  \n  #clean up names\n  step_rename(\n    isHoliday = Holiday_Holiday,\n    isWeekend = Weekday_Weekend_Weekend,\n    isSummerSeason = Seasons_Summer,\n    isSpringSeason = Seasons_Spring,\n    isAutumnSeason = Seasons_Autumn\n  )\n    \n    \n   # ) |&gt;  prep(training=data_train) |&gt;\n #bake(data_train)\n#testing |&gt; summary()\n\n\n\n\nFor this recipe, we start with Recipe 1 and add interaction terms between:\n\nseasons and holiday\nseasons and temp\ntemp and rainfall\n\n\nrecipe2 &lt;- recipe1 |&gt;\n  step_interact(terms = ~\n                  ends_with(\"Season\") *\n                  ends_with(\"Holiday\") \n                ) |&gt;\n  step_interact(terms = ~\n                  ends_with(\"Season\") *\n                  TemperatureAvg\n                ) |&gt;\n  step_interact(terms = ~\n                  TemperatureAvg *\n                  RainfallSum\n                ) \n\n\n\n\nFor the third recipe, start from Recipe 2 and add quadratic terms for each numeric predictor. Since our dummy variables are technically numeric now, I’m excluding them by avoiding all those beginning with is (like isSpring, etc.).\n\nrecipe3 &lt;- recipe2 |&gt;\n  step_poly(\n    all_numeric_predictors(),\n    -starts_with(\"is\"),\n    degree=2\n    )\n\n\n\n\nWe will fit the models using linear lm engine and use 10-fold CV to calculate error.\nFirst, define the model engine.\n\ndata_model &lt;- linear_reg() |&gt;\n  set_engine(\"lm\")\n\nNext, define workflows for each recipe.\n\ndata_workflow1 &lt;- workflow() |&gt;\n  add_recipe(recipe1) |&gt;\n  add_model(data_model)\n\ndata_workflow2 &lt;- workflow() |&gt;\n  add_recipe(recipe2) |&gt;\n  add_model(data_model)\n\ndata_workflow3 &lt;- workflow() |&gt;\n  add_recipe(recipe3) |&gt;\n  add_model(data_model)\n\nNow, define and run the 10-fold CV for each. Out of curiosity, I am going to compare to a non-CV run as well.\n\n#non-CV for simple recipe 1\ndata_fit_nonCV &lt;- data_workflow1 |&gt;\n  fit(data_train)\n\n#data_fit_nonCV |&gt;\n# tidy()\n\n#10fold CV for each recipe\nrecipe1_10Fold_metrics &lt;- data_workflow1 |&gt;\n  fit_resamples(data_train_10Fold) |&gt;\n  collect_metrics()\n\nrecipe2_10Fold_metrics &lt;- data_workflow2 |&gt;\n  fit_resamples(data_train_10Fold) |&gt;\n  collect_metrics()\n\n→ A | warning: prediction from rank-deficient fit; consider predict(., rankdeficient=\"NA\")\n\n\nThere were issues with some computations   A: x1\nThere were issues with some computations   A: x1\n\n\n\n\nrecipe3_10Fold_metrics &lt;- data_workflow3 |&gt;\n  fit_resamples(data_train_10Fold) |&gt;\n  collect_metrics()\n\n→ A | warning: prediction from rank-deficient fit; consider predict(., rankdeficient=\"NA\")\n\n\nThere were issues with some computations   A: x1\nThere were issues with some computations   A: x1\n\n\n\n\nrbind(\n  recipe1_10Fold_metrics,\n  recipe2_10Fold_metrics,\n  recipe3_10Fold_metrics\n)\n\n# A tibble: 6 × 6\n  .metric .estimator     mean     n  std_err .config             \n  &lt;chr&gt;   &lt;chr&gt;         &lt;dbl&gt; &lt;int&gt;    &lt;dbl&gt; &lt;chr&gt;               \n1 rmse    standard   4070.       10 165.     Preprocessor1_Model1\n2 rsq     standard      0.840    10   0.0106 Preprocessor1_Model1\n3 rmse    standard   3074.       10 252.     Preprocessor1_Model1\n4 rsq     standard      0.900    10   0.0184 Preprocessor1_Model1\n5 rmse    standard   2984.       10 196.     Preprocessor1_Model1\n6 rsq     standard      0.907    10   0.0152 Preprocessor1_Model1\n\n\nThe best model of the three looks like the third recipe, with interaction terms and quadratic terms.\n\n\n\n\nNow, let’s fit it to the entire training dataset and compute RMSE.\n\nbest_fit &lt;- data_workflow3 |&gt;\n  last_fit(data_split)\nbest_fit |&gt; collect_metrics()\n\n# A tibble: 2 × 4\n  .metric .estimator .estimate .config             \n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt; &lt;chr&gt;               \n1 rmse    standard    2964.    Preprocessor1_Model1\n2 rsq     standard       0.910 Preprocessor1_Model1\n\n\nHere is the coefficient table for our model, arranged by p-values to highlight the most predictive parameters.\n\nextract_fit_parsnip(best_fit) |&gt; tidy() |&gt; arrange(p.value)\n\n# A tibble: 30 × 5\n   term                            estimate std.error statistic  p.value\n   &lt;chr&gt;                              &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n 1 isSummerSeason                    24955.     2078.     12.0  3.53e-26\n 2 SolarRadiationAvg_poly_1          54739.     5764.      9.50 2.74e-18\n 3 isWeekend                         -2458.      411.     -5.98 8.21e- 9\n 4 isAutumnSeason                    11823.     2268.      5.21 4.09e- 7\n 5 isSpringSeason_x_TemperatureAvg   10048.     2464.      4.08 6.23e- 5\n 6 RainfallSum_poly_1               -34844.     8953.     -3.89 1.30e- 4\n 7 (Intercept)                        9828.     2675.      3.67 2.97e- 4\n 8 isSpringSeason                     6669.     2170.      3.07 2.36e- 3\n 9 HumidityAvg_poly_1               -56014.    24608.     -2.28 2.37e- 2\n10 DewPointAvg_poly_1               173117.    82435.      2.10 3.68e- 2\n# ℹ 20 more rows\n\n\nSo, recalling what we are doing here - predicting bike rental volume - it is interesting to note the predictors most likely to relate to bike rental volumes. I think that’s what the lowest p-values represent here, the likelihood that this was a random relationship (slope of zero) with the outcome.\n\nif we are in summer, we are likely to see more rentals\nsolar radiation increases with rentals, too (related to summer)\non the weekend, we are less likely to see rentals? That surprises me, so I checked my setup to be sure.\nif raining, less bikes; this makes sense."
  }
]